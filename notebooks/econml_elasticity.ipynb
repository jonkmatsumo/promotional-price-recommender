{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Price Elasticity Estimation with Double Machine Learning (EconML)\n",
                "\n",
                "This notebook demonstrates how to use **Double Machine Learning (DML)** to estimate price elasticity for Video-on-Demand (VOD) titles. Unlike standard churn models which predict *risk*, this model predicts *sensitivity to price*, allowing us to find the revenue-maximizing price for each user.\n",
                "\n",
                "### Workflow\n",
                "1. **Data Generation**: Create synthetic data with continuous pricing and hidden confounding (e.g., peak demand bias).\n",
                "2. **DML Modeling**: Use `EconML`'s `LinearDML` or `CausalForestDML` to estimate elasticity ($\\theta(X)$).\n",
                "3. **Optimization**: Use the estimated elasticity to calculate the optimal price point for each user.\n",
                "4. **Evaluation**: Compare estimated elasticity against the ground truth from our Oracle."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append(os.path.abspath(\"../src\"))\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from vod_causal.data.generator import VODSyntheticData\n",
                "from vod_causal.models.dml import DMLWithEconML\n",
                "from revenue_optimizer import bulk_optimize\n",
                "\n",
                "%matplotlib inline\n",
                "sns.set_style(\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Generate Synthetic Data with Pricing Bias\n",
                "\n",
                "We generate 5,000 users and 20,000 interactions. \n",
                "**Crucial:** The data generator now simulates \"confounding\":\n",
                "- Users with high watch time (loyal) are offered *higher* prices (or smaller discounts) on average.\n",
                "- This simulates a naive algorithm attempting to maximize immediate revenue.\n",
                "- A simple regression would incorrectly conclude that \"higher prices -> higher purchase probability\" (because loyal users buy anyway)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "generator = VODSyntheticData(n_users=5000, n_titles=100, n_interactions=20000, seed=42)\n",
                "data_dict = generator.generate_all()\n",
                "df = generator.create_modeling_dataset(data_dict)\n",
                "\n",
                "print(f\"Dataset shape: {df.shape}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Inspect Confounding\n",
                "Let's see if our generator successfully introduced bias. We expect higher prices for users with higher `avg_daily_watch_time`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "sns.scatterplot(data=df.sample(2000), x=\"avg_daily_watch_time\", y=\"offered_price\", alpha=0.3)\n",
                "plt.title(\"Confounding Check: Watch Time vs. Offered Price\")\n",
                "plt.xlabel(\"Avg Daily Watch Time (min)\")\n",
                "plt.ylabel(\"Offered Price ($)\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Train Double Machine Learning Model\n",
                "\n",
                "We use `LinearDML` from `econml`. \n",
                "\n",
                "**The Causal Question:**\n",
                "- **T (Treatment):** `offered_price` (Continuous)\n",
                "- **Y (Outcome):** `did_rent` (Binary 0/1)\n",
                "- **X (Effect Modifiers):** `price_sensitivity`, `subscription_tenure_months`, `avg_daily_watch_time`, `geo_region`\n",
                "- **W (Controls):** Genre, Popularity, Director"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare features\n",
                "feature_cols = [\"price_sensitivity\", \"subscription_tenure_months\", \"avg_daily_watch_time\"]\n",
                "control_cols = [\"is_cold_start\", \"base_popularity\", \"release_year\"]\n",
                "\n",
                "# One-Hot Encoding for categorical regions\n",
                "X = pd.get_dummies(df[feature_cols + [\"geo_region\"]], columns=[\"geo_region\"], drop_first=True)\n",
                "W = df[control_cols]\n",
                "T = df[\"offered_price\"]\n",
                "Y = df[\"did_rent\"]\n",
                "\n",
                "print(\"Training DML Model (this may take a minute)...\")\n",
                "# We use 'forest' (CausalForestDML) for better heterogeneity detection, \n",
                "# or 'linear' for speed and interpretability. Let's start with LinearDML wrapped in our class.\n",
                "dml = DMLWithEconML(model_type=\"linear\", n_folds=3, random_state=42)\n",
                "dml.fit(X, T, Y, W=W)\n",
                "\n",
                "print(\"Model Fitted!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Analyze Estimated Elasticity\n",
                "\n",
                "Let's look at the estimated elasticity coefficients. Remember, a **more negative** value means **higher sensitivity** (demand drops faster as price increases)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predict elasticity for the training set\n",
                "elasticities = dml.effect(X)\n",
                "\n",
                "# Add to dataframe for analysis\n",
                "df[\"predicted_elasticity\"] = elasticities\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "sns.histplot(df[\"predicted_elasticity\"], kde=True, bins=30)\n",
                "plt.title(\"Distribution of Predicted Price Elasticity\")\n",
                "plt.xlabel(\"Elasticity (Change in Prob per $1 Increase)\")\n",
                "plt.axvline(x=0, color='red', linestyle='--')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Validation: Does it match ground truth?\n",
                "In synthetic data, we know the `true_elasticity`. Let's compare."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    # If true_elasticity column exists (updated generator)\n",
                "    plt.figure(figsize=(8, 8))\n",
                "    sns.scatterplot(x=df[\"true_elasticity\"], y=df[\"predicted_elasticity\"], alpha=0.1)\n",
                "    plt.plot([df[\"true_elasticity\"].min(), df[\"true_elasticity\"].max()], \n",
                "             [df[\"true_elasticity\"].min(), df[\"true_elasticity\"].max()], \n",
                "             color='red', linestyle='--')\n",
                "    plt.title(\"Predicted vs. True Elasticity\")\n",
                "    plt.xlabel(\"True Elasticity (Oracle)\")\n",
                "    plt.ylabel(\"Predicted Elasticity (DML)\")\n",
                "    plt.show()\n",
                "except KeyError:\n",
                "    print(\"Column 'true_elasticity' not found in dataset. Ensure generator code is updated.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Revenue Optimization\n",
                "\n",
                "Now we use the `revenue_optimizer` to find the best price for each user."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select a sample of users\n",
                "sample_users = X.iloc[:100].copy()\n",
                "\n",
                "# Run bulk optimization\n",
                "optimization_results = bulk_optimize(sample_users, dml, base_probas=None)\n",
                "\n",
                "optimization_results.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Recommended Prices Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 5))\n",
                "sns.histplot(optimization_results[\"optimal_price\"], bins=15)\n",
                "plt.title(\"Distribution of Optimized Prices\")\n",
                "plt.xlabel(\"Recommended Price ($)\")\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}